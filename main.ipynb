{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar IF3270 Pembelajaran Mesin Bag.A\n",
    "\n",
    "Anggota Kelompok:\n",
    "1. 13520039 - Rozan Fadhil Al Hafidz\n",
    "1. 13520054 - Farrel Farandieka Fibriyanto\n",
    "1. 13520103 - Amar Fadil\n",
    "1. 13520105 - Malik Akbar Hashemi Rafsanjani"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teori Dasar\n",
    "\n",
    "### FFNN\n",
    "Atau Feed Forward Neural Network merupakan jenis model artificial neural network yang tidak mengandung siklus dan termasuk model yang paling sederhana karena memproses informasi ke satu arah saja.\n",
    "\n",
    "![Sample-of-a-feed-forward-neural-network.png](https://www.researchgate.net/profile/Ramon-Quiza/publication/234055177/figure/fig1/AS:300092981563410@1448559150651/Sample-of-a-feed-forward-neural-network.png)\n",
    "\n",
    "Sumber: [Quiza, R.](https://www.researchgate.net/figure/Sample-of-a-feed-forward-neural-network_fig1_234055177)\n",
    "\n",
    "Terdapat 3 layer dalam ilustrasi di atas:\n",
    "1. Input Layer:\n",
    "    - layer yang menerima input atau fitur dari data\n",
    "2. Hidden Layer:\n",
    "    - layer yang berada diantara input dan output layer\n",
    "    - layer yang melakukan proses pembelajaran mesin melalui forward propagation serta activation function\n",
    "    - Bisa memiliki lebih dari satu layer\n",
    "    - Tidak terlihat saat proses pembelajaran\n",
    "3. Output Layer\n",
    "    - layer yang menghasilkan output dari data\n",
    "    - Jumlah neuron di output layer sama dengan jumlah kelas yang akan diprediksi\n",
    "\n",
    "### Activation Function\n",
    "Fungsi Aktivasi biasanya dipakai dalam arsitektur ketika terjadi perpindahan layer, sebelum nilai output diberikan ke layer berikutnya akan dilalui fungsi aktivasi terlebih dahulu. Fungsi aktivasi ini biasanya digunakan untuk menambahkan sifat non-linearitas pada neural network. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "import json\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelas activations akan menyimpan fungsi aktivasi yang dapat dipakai oleh kelas neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activations:\n",
    "    def softmax(x):\n",
    "        return np.exp(x)  \n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def sign(x):\n",
    "        return 1 if x > 0 else -1\n",
    "\n",
    "    def linear(x):\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelas JsonReader bertanggung jawab untuk membaca fail json yang menyimpan kriteria model dengan format yang kami tetapkan sendiri. Dengan kelas ini, program dapat me-load model-model yang telah ditetapkan di fail json eksternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonReader:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "\n",
    "    def read(self):\n",
    "        with open(self.filename, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def get(self, index: int):\n",
    "        return self.data[index]\n",
    "\n",
    "    def length(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat 3 kelas utama yang akan digunakan dalam implementasi: Model, Layer, dan Neuron. \n",
    "Ketiga kelas akan bersifat dengan entitas dengan nama yang sama seperti di arsitektur neural network biasanya. Suatu fungsi aktivasi akan disimpan di daftar fungsi aktivasi sehingga dapat di-invoke oleh kelas neuron.\n",
    "\n",
    "Kelas neuron akan menyimpan weight yang telah ditetapkan sebelumnya dan menghitung nilai output berdasarkan nilai weight tadi, sebuah fungsi aktivasi, dan nilai masukan yang berasal dari masukan model seluruhnya atau hasil output layer sebelumnya di model.\n",
    "\n",
    "Kelas layer akan menyimpan beberapa kelas neuron sehingga membentuk suatu layer penuh. Kelas ini juga dapat menghasilkan array berupa output neuron yang dimiliki kelas tersebut. Dengan ini, kelas ini bisa menghasilkan nilai yang akan dapat dijadikan masukan layer berikutnya atau, apabila sudah merupakan layer terakhir, menjadi output dari model seluruhnya.\n",
    "\n",
    "Kelas model akan menyimpan beberapa kelas layer yang dapat dipakai untuk menghitung perhitungan prediksi model tersebut. Kelas model akan menerima nilai masukan dari pengguna dan kemudian mengiterasi dari layer paling awal untuk menghitung nilai keluaran dari layer tersebut untuk kemudian dijadikan parameter untuk layer berikutnya, dan seterusnya sampai sampai ke layer terakhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        activation: Callable | str = 'sigmoid',\n",
    "        weights: list[float] = None,\n",
    "    ):\n",
    "        self.activation = activation\n",
    "        if isinstance(activation, str):\n",
    "            self.activation: Callable = getattr(activations, activation)\n",
    "        self.weights = weights\n",
    "        self.value = 0\n",
    "\n",
    "    def __call__(self, x: list[float]):\n",
    "        # feed forward\n",
    "        val = np.dot(x, self.weights)\n",
    "        self.value = self.activation(val)\n",
    "        return self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Neuron({self.activation.__name__}, {self.weights})'\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        neurons: list[Neuron] | int,\n",
    "        name: str = '',\n",
    "        activation: Callable | str = '',\n",
    "        weights: list[list[float]] = None,\n",
    "        bias: float = 1,\n",
    "        input_shape=0,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.activation = activation\n",
    "        if isinstance(activation, str):\n",
    "            self.activation: Callable = getattr(activations, activation)\n",
    "        self.neurons = neurons\n",
    "        if isinstance(neurons, int):\n",
    "            self.neurons: list[Neuron] = [\n",
    "                Neuron(activation, weights[i] if weights else 0)\n",
    "                for i in range(neurons)\n",
    "            ]\n",
    "        self.bias = bias\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def get_output_shape(self):\n",
    "        return len(self.neurons)\n",
    "\n",
    "    def get_params_count(self):\n",
    "        return (len(self.neurons) + 1) * self.input_shape\n",
    "\n",
    "    def get_weights(self):\n",
    "        return np.array([neuron.weights for neuron in self.neurons])\n",
    "\n",
    "    def __call__(self, inputs: list[float]) -> list[float]:\n",
    "        # feed forward\n",
    "        out = [neuron(inputs) for neuron in self.neurons]\n",
    "        if self.activation is activations.softmax:\n",
    "            out = (out / sum(out)).tolist()\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        activation_name = self.activation.__name__\n",
    "        weights = self.get_weights()\n",
    "        param_count = (len(weights) + 1) * self.input_shape\n",
    "\n",
    "        return ''.join([\n",
    "            'Layer(',\n",
    "            f'activation={activation_name},',\n",
    "            f'weights={weights},',\n",
    "            f'bias={self.bias},',\n",
    "            f'param_count={param_count}',\n",
    "            ')',\n",
    "        ])\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, layers: list[Layer] = None) -> None:\n",
    "        self.layers = layers\n",
    "        if layers is None:\n",
    "            self.layers: list[Layer] = []\n",
    "\n",
    "    def add(self, layer: Layer) -> None:\n",
    "        if self.layers:\n",
    "            layer.input_shape = self.layers[-1].get_output_shape()\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def get_params_count(self):\n",
    "        return sum([layer.get_params_count() for layer in self.layers])\n",
    "\n",
    "    def summary(self):\n",
    "        print(f'Model with {self.get_params_count()} parameters')\n",
    "        for layer in self.layers:\n",
    "            print(layer)\n",
    "\n",
    "    def __call__(self, inputs: list[list[float]]):\n",
    "        # feed forward\n",
    "        outputs: list[list[float]] = []\n",
    "        for input in inputs:\n",
    "            out = input\n",
    "            for layer in self.layers:\n",
    "                out.append(1)\n",
    "                out = layer(out)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelas ModelFactory akan membuat model-model yang dapat dipakai secara langsung. Kelas ini dapat menerima masukan suatu nama fail ketika di-invoke dan akan mengembalikan model yang telah dibuat sesuai dengan kriteria yang telah ditetapkan di fail json eksternal tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFactory:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.json_reader = JsonReader(f'{model_name}.json')\n",
    "        self.model = None\n",
    "\n",
    "    def create(self) -> Model:\n",
    "        self.json_reader.read()\n",
    "        self.model = Model()\n",
    "        for i in range(self.json_reader.length()):\n",
    "            layer = self.json_reader.get(i)\n",
    "            self.model.add(Layer(\n",
    "                layer['neurons'],\n",
    "                input_shape=layer['neurons'] + 1,\n",
    "                activation=layer['activation'],\n",
    "                weights=layer['weights'],\n",
    "                bias=layer['bias'],\n",
    "            ))\n",
    "        return self.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelas ModelTester merupakan kelas yang membantu untuk melakukan pengetesan terhadap hasil model yang telah dibuat. Kelas ini akan menerima masukan berupa model yang akan diuji, data yang akan diuji, dan label yang akan diuji. Kelas ini akan menghitung akurasi dari model yang telah dibuat menggunakan nilai SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, max_sse: float = 0.000001):\n",
    "        self.max_sse = max_sse\n",
    "    \n",
    "    def calculate_sse(\n",
    "        self, \n",
    "        predicted_result: list[list[float]], \n",
    "        expected_result: list[list[float]]) -> float:\n",
    "        return sum([sum([(predicted_result[i][j] - expected_result[i][j]) ** 2 for j in range(len(predicted_result[i]))]) for i in range(len(predicted_result))])\n",
    "\n",
    "    def test(self, predicted_result: list[list[float]], expected_result: list[list[float]]) -> bool:\n",
    "        sse = self.calculate_sse(predicted_result, expected_result)\n",
    "        print(f'SSE: {sse}')\n",
    "        print(f'Max SSE: {self.max_sse}')\n",
    "        print(f'Is SSE less than max SSE? {sse < self.max_sse}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = ModelTester(0.000001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 16 parameters\n",
      "Layer(activation=relu,weights=[[ 0.4  0.7  0.1]\n",
      " [-0.5  0.8  0.2]\n",
      " [ 0.6 -0.9  0.3]],bias=1,param_count=16)\n",
      "\n",
      "Predicted Data: [[0.04999999999999996, 1.1, 0.0]]\n",
      "SSE: 1.7333369499485123e-33\n",
      "Max SSE: 1e-06\n",
      "Is SSE less than max SSE? True\n"
     ]
    }
   ],
   "source": [
    "model_name = 'test/relu'\n",
    "\n",
    "model_factory = ModelFactory(model_name)\n",
    "model = model_factory.create()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "data = [[-1.0, 0.5]]\n",
    "expected_output = [[0.05, 1.1, 0.0]]\n",
    "trained = model(data)\n",
    "print(f'Predicted Data: {trained}')\n",
    "\n",
    "tester.test(trained, expected_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 16 parameters\n",
      "Layer(activation=sigmoid,weights=[[0.2 0.1 0.4]\n",
      " [0.4 0.2 0.2]\n",
      " [0.2 0.4 0.1]],bias=1,param_count=16)\n",
      "\n",
      "Predicted Data: [[0.617747874769249, 0.5890404340586651, 0.574442516811659]]\n",
      "SSE: 1.2207224545374987e-12\n",
      "Max SSE: 1e-06\n",
      "Is SSE less than max SSE? True\n"
     ]
    }
   ],
   "source": [
    "model_name = 'test/sigmoid'\n",
    "\n",
    "model_factory = ModelFactory(model_name)\n",
    "model = model_factory.create()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "data = [[0.2, 0.4]]\n",
    "expected_output = [[0.617747, 0.589040, 0.574442]]\n",
    "trained = model(data)\n",
    "print(f'Predicted Data: {trained}')\n",
    "\n",
    "tester.test(expected_output, trained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 16 parameters\n",
      "Layer(activation=linear,weights=[[ 0.5  0.3  0.2]\n",
      " [ 0.2 -0.6  0.3]\n",
      " [-0.8  0.4  0.1]],bias=1,param_count=16)\n",
      "\n",
      "Predicted Data: [[2.0, 0.3000000000000001, -1.9000000000000004]]\n",
      "SSE: 2.0954117794933126e-31\n",
      "Max SSE: 1e-06\n",
      "Is SSE less than max SSE? True\n"
     ]
    }
   ],
   "source": [
    "model_name = 'test/linear'\n",
    "\n",
    "model_factory = ModelFactory(model_name)\n",
    "model = model_factory.create()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "data = [[3.0, 1.0]]\n",
    "expected_output = [[ 2.0,  0.3, -1.9]]\n",
    "trained = model(data)\n",
    "print(f'Predicted Data: {trained}')\n",
    "\n",
    "tester.test(expected_output, trained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 15 parameters\n",
      "Layer(activation=linear,weights=[[ 0.  -1.   0.5]\n",
      " [-2.   0.   0.5]],bias=1,param_count=9)\n",
      "Layer(activation=relu,weights=[[ 0.  -1.   0.5]\n",
      " [-3.   0.   0.5]],bias=1,param_count=6)\n",
      "\n",
      "Predicted Data: [[2.0, 0.0], [0.0, 2.0], [0.0, 0.0]]\n",
      "SSE: 0.0\n",
      "Max SSE: 1e-06\n",
      "Is SSE less than max SSE? True\n"
     ]
    }
   ],
   "source": [
    "model_name = 'test/multilayer'\n",
    "\n",
    "model_factory = ModelFactory(model_name)\n",
    "model = model_factory.create()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "data = [\n",
    "            [1.0, 0.0],\n",
    "            [0.0, 1.0],\n",
    "            [0.0, 0.0]\n",
    "        ]\n",
    "expected_output = [\n",
    "            [2.0, 0.0],\n",
    "            [0.0, 2.0],\n",
    "            [0.0, 0.0]\n",
    "        ]\n",
    "trained = model(data)\n",
    "print(f'Predicted Data: {trained}')\n",
    "\n",
    "tester.test(expected_output, trained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 16 parameters\n",
      "Layer(activation=softmax,weights=[[2. 3. 1.]\n",
      " [1. 2. 2.]\n",
      " [3. 1. 3.]],bias=1,param_count=16)\n",
      "\n",
      "Predicted Data: [[0.6652409557748219, 0.09003057317038045, 0.24472847105479764]]\n",
      "SSE: 4.0603201288236806e-13\n",
      "Max SSE: 1e-06\n",
      "Is SSE less than max SSE? True\n"
     ]
    }
   ],
   "source": [
    "model_name = 'test/softmax'\n",
    "\n",
    "model_factory = ModelFactory(model_name)\n",
    "model = model_factory.create()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "data = [[1.0, 2.0]]\n",
    "expected_output = [[0.665241, 0.090031, 0.244728]]\n",
    "trained = model(data)\n",
    "print(f'Predicted Data: {trained}')\n",
    "\n",
    "tester.test(expected_output, trained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kesimpulan\n",
    "\n",
    "Semua fungsi aktivasi yang telah kami uji berhasil menghasilkan nilai yang diharapkan, yaitu di bawah nilai SSE_MAX yang telah ditetapkan. Fungsi aktivasi yang paling baik adalah fungsi aktivasi Relu karena memiliki nilai akurasi yang paling tinggi dengan penilaian SSE. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perbandingan Dengan Perhitungan Manual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua perhitungan terdapat di [Google Sheets](https://docs.google.com/spreadsheets/d/1oL4xwHmo1vg2l9TfZALkG3r50B6X6OfhrNQb0RehOXE/edit?usp=sharing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu\n",
    "\n",
    "![img](https://media.discordapp.net/attachments/1093487471016300545/1093487491287367752/image.png?width=562&height=228)\n",
    "\n",
    "#### Sigmoid\n",
    "![img](https://media.discordapp.net/attachments/1093487471016300545/1093487950131642478/image.png?width=558&height=218)\n",
    "\n",
    "#### Linear\n",
    "![img](https://media.discordapp.net/attachments/1093487471016300545/1093488338968784926/image.png?width=567&height=216)\n",
    "\n",
    "#### MultiLayer\n",
    "![img](https://media.discordapp.net/attachments/1093487471016300545/1093488115081031731/image.png?width=359&height=699)\n",
    "\n",
    "#### Softmax\n",
    "![img](https://media.discordapp.net/attachments/1093487471016300545/1093488157779054693/image.png?width=559&height=245)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kesimpulan\n",
    "Model yang kami hasilkan memiliki nilai yang sama atau mendekati dengan hasil perhitungan manual. Apabila terdapat perbedaan, perbedaan tersebut dapat disebabkan dari pembulatan nilai serta penggunaan kalkulasi menggunakan float. Perbedaan nilai yang kami dapatkan juga tidak berbeda jauh dibandingkan nilai ekspektasi yang telah ditetapkan asisten sebelumnya"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembagian Tugas \n",
    "\n",
    "1. 13520039 - External Model Reader \n",
    "1. 13520054 - Docs and Testing \n",
    "1. 13520103 - Structure and Base Class\n",
    "1. 13520105 - Activation and Inference "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
